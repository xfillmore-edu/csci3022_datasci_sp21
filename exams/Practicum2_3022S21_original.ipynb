{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3022: Intro to Data Science - Spring 2021 Practicum 2\n",
    "***\n",
    "\n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own. \n",
    "2. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "3. This is meant to be like a coding portion of your midterm exam. So, the instructional team will be a bit less helpful than we typically are with homework. For example, we will not check answers, significantly debug your code, and so on.  But please don't feel like you're totally alone on this: **feel free to ask questions or ask for help**, and we will decide how best to provide that assistance.\n",
    "4. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions though.\n",
    "5. You may **NOT** post to message boards or other online resources asking for help, except Piazza.\n",
    "6. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "7. You may **NOT** collaborate with classmates or anyone else.\n",
    "8. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on this practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "***\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the practicums nor can you drop your practicum grades. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread.\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. The practicum is designed to be completed using only the packages in the first given code cell.\n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Bottom](#bot)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zacha\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "##Get them stats in here\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pylab as plt \n",
    "from patsy import dmatrices\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p1'></a>\n",
    "\n",
    "## [50 points] Problem 1: What makes a good shuffle?\n",
    "\n",
    "Our goal in this problem is understand something about the statistics of shuffling: what makes a good shuffle?  Can we compare the order of cards in the deck to an original (sorted) order to determine whether or not the deck appears randomized?\n",
    "\n",
    "In all cases in this problem, we can view a deck as having all unique cards: the standard 52-card playing deck could be represented by integer card identifiers $[0, 1, 2, 3, \\dots, 51]$, and a *shuffle* of the deck is a random *permutation* of those 52 indentifiers.\n",
    "\n",
    "In part 1 of this problem, we explore a sample statistic that reduces the order of the cards into a single measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Part 1: The Statistic\n",
    "** Part 1 A: Implementing the statistic.**\n",
    "\n",
    "The most common *single* statistic used for tracking the randomness of a shuffle is the count of *rising sequences* in that list's indices.  A rising sequence is a sequence of cards that appear in the same order that they did in the original deck, even if some other cards are in between.  For example, if the deck is represented by integers 0-10, card '1' will be part of the same rising sequence as card '0' as long as '1' occurs after '0' in the shuffled deck.  '2' would be part of the same sequence as long as it is after '1'.\n",
    "\n",
    "A visualization of counting these can be found on page 2 [of this paper](https://statweb.stanford.edu/~cgates/PERSI/papers/bayer92.pdf).  **Look over the images in the paper before proceeding.**\n",
    "\n",
    "\n",
    "\n",
    "Implement the `rising_seqs` function that takes in a list of integers and returns the number of rising sequences of that list.\n",
    "\n",
    "Overview of the function:\n",
    "- Find the indices for the permutation of deck that *would* represent a perfect sort of the deck.   Check `np.argsort` for a quick way to do this.  For example, the deck [3,0,2,1] has sorted permutation of [1,3,2,0], since we find the value 0 in index 1, then the value 1 in index 3, and so forth.\n",
    "- Count the number of times that the indices in this permutation decrease; e.g. the number of times that index $i$ has a value *more* than index $i+1$.  This represents a location where in the **shuffled** deck, a rising sequence would have been broken or ended, requiring us to start a new sequence.  The total count of rising sequences is 1 plus this value.\n",
    "- Return the number of rising sequences.\n",
    "- You may assume the deck's values are all integers and begin at 0, although neither assumption should be necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_seqs(deck):\n",
    "    #your code here\n",
    "    return drops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 B: Trying out the statistic.**\n",
    "\n",
    "Try out your statistic on a few quick test cases to make sure it's working.\n",
    "\n",
    "Some examples to sanity check your function.\n",
    "- [0,1,2,3,4,5,6,7] has only one rising sequence.\n",
    "- [7,6,5,4,3,2,1,0] has 8 rising sequences: each term is its own.\n",
    "- [3,1,2,0] has 3 rising sequence: [0], [1,2], [3].\n",
    "- [0,2,3,5,1,4,7,6] has the 4 rising sequences of [0,1], [2,3,4], [5,6], and [7].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-21230aa66765>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrising_seqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtest1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Failed check 1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrising_seqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtest2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Failed check 2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3408ba38169f>\u001b[0m in \u001b[0;36mrising_seqs\u001b[1;34m(deck)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrising_seqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdrops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'drops' is not defined"
     ]
    }
   ],
   "source": [
    "test1=rising_seqs(np.array([0, 1, 2, 3, 4, 5, 6, 7]))\n",
    "assert test1 == 1, 'Failed check 1'\n",
    "\n",
    "test2=rising_seqs(np.array([7,6,5,4,3,2,1,0]))\n",
    "assert test2 == 8, 'Failed check 2'\n",
    "\n",
    "test3=rising_seqs(np.array([3,1,2,0]))\n",
    "assert test3 == 3, 'Failed check 3'\n",
    "\n",
    "test4=rising_seqs(np.array([0,2,3,5,1,4,7,6]))\n",
    "assert test4 == 4, 'Failed check 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 C: Bootstrapping.**\n",
    "\n",
    "What represents a well shuffled deck?  Take a 52-card deck (or the integer list $[0,1,2,\\dots ,51]$) and use np.random.shuffle or np.random.permutation to generate 10000 random permutations.  For each, compute and save their counts of rising sequences.\n",
    "\n",
    "Make a histogram of those rising sequences and print out the mean, 2.5\\% percentile and 97.5\\% percentile.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 D: The Bootstrapped test.**\n",
    "    \n",
    "We wish to test the null hypothesis \"the deck is well-shuffled\" against the alternative \"the deck is not well-shuffled,\" using the *test statistic* of rising sequences.  In plain English, what is the *rejection rejection* of such a test?  When would we decide that a given ordering is not a good shuffle?  Use a 95% significance, as suggested by the interval in part 1C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Part 2: How to Shuffle\n",
    "\n",
    "A \"perfect riffle\" shuffle is a shuffle in which a deck is divided exactly in half, and then a new deck order is formed by alternating one-card-at-a-time from each half.  Depending on whether or not the top or first card of the interleaving came from the top half of the deck or the bottom half of the deck this is called an *out-shuffle* or *in-shuffle*, respectively.\n",
    "\n",
    "** Part 2 A: The out-shuffle.**\n",
    "\n",
    "Write a function that performs a perfect out-shuffle of a deck.  This function should take an ordered list of length $n$ and:\n",
    "\n",
    "- breaks the deck in half, with the \"top\" of the deck being the first $n/2$ elements and the \"bottom\" of the deck being the last $n/2$ elements.\n",
    "- creates a new ordered list generated by interweaving one card from the top pile, *then* one card from the \"bottom\" pile, etc.  The top/first card comes from the \"top\" elements and the bottom/last card comes from the \"bottom\" pile.\n",
    "\n",
    "You may for convenience assume that there are an even number of cards in the deck.\n",
    "\n",
    "(Note and sanity check: a perfect out-shuffle on a deck with an even number of cards will always have the first card of the input ordering remain the first card of the output ordering, and the input last card remain the last card)\n",
    ".\n",
    "In the suggested API:\n",
    " - deck is a numpy array of integers (or floats) from 0 to (n-1) for a deck of length n.  Consider using np.array(range(n)) if you want to initialize a sorted deck.\n",
    " - Return statement is a numpy array of the same form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommended API for checks:\n",
    "def out_shuffle(deck):\n",
    "    #your code here!\n",
    "    return new_deck\n",
    "# out_shuffle(np.array(range(10))) sanity check: should be 0-5-1-6..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 2 B: Counting out-shuffles.**\n",
    "\n",
    "How much are we supposed to shuffle?  Beginning with a sorted deck $[0,1,2,\\dots ,51]$, perform out-shuffles 52 times *in a row*, where the result of one shuffle is used as the input/start for another.  For each resulting state of the deck, do the following:\n",
    "\n",
    "- save the number of rising sequences in the deck\n",
    "- Perform a formal hypothesis test using the bootstrapped rejection region in part a): at 95\\% confidence would we reject the null hypothesis that \"the deck is well-shuffled?.\"\n",
    "- Compute a two-tailed p-value for the number of rising sequences in the deck.  In other words, what proportion of the time in the simulated `np.random.shuffle` shuffles did we observe a more extreme number of rising sequences?\n",
    "\n",
    "Make a plot with \"number of perfect out shuffles\" on the $x$-axis and \"rising sequences\" for the shuffle on the $y$-axis.  Include a visual indicator for when the number of rising sequences was *inside* or *outside* of the rejection region in part 1.\n",
    "\n",
    "Using this plot make a plain English statment answering the following: \"What is the best number of shuffles to approximately randomize a sorted deck using out-shuffles?  Does it end up well randomized?\"  Explain your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 2 C: In-shuffles.**\n",
    "\n",
    "Repeat parts 2A and 2B for in shuffles.  This means do the following:\n",
    "\n",
    "Write a function that performs a perfect in-shuffle of a deck.  This function should take an ordered list of length $n$ and:\n",
    "\n",
    "- breaks the deck in half, with the \"top\" of the deck being the first $n/2$ elements and the \"bottom\" of the deck being the last $n/2$ elements.\n",
    "- creates a new ordered list generated by interweaving one card from the bottom pile, *then* one card from the \"top\" pile, etc.  The top/first card comes from the \"bottom\" elements and the bottom/last card comes from the \"top\" pile.\n",
    "\n",
    "After this, repeat the plot and hypothesis tests made in part 2B for the in-shuffle.  Again, answer the prompt:  \"What is the best number of shuffles to approximately randomize a sorted deck using in-shuffles?  Does it end up well randomized?\"  Explain your answer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommended API for checks:\n",
    "def in_shuffle(deck):\n",
    "    #your code here!\n",
    "    return new_deck\n",
    "# in_shuffle(np.array(range(10))) sanity check: should be 5-0-6-1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "#make plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Part 3: Noisy Shuffling; Extra Credit\n",
    "** Part 3 A: Random shuffles; Extra Credit**\n",
    "\n",
    "**This part of the problem is for extra credit only.  It is not required.** \n",
    "\n",
    "One result of your analysis above should have been that \"perfect\" shuffles aren't great for getting a random deck - we only approximate randomness and eventually find our way back into the original sort. So how do we shuffle better?  Suppose that we divide our deck in half as we prepare to shuffle, but then *instead* of one-by-one interleaving the two piles, we choose a random number of cards from each pile before we move to the other pile.\n",
    "\n",
    "A variety of ways to describe this exist, but let's try one: Poissons.\n",
    "\n",
    "Create a function `rand_in_shuffle(deck, lambda)` that starts with your code for an in-shuffle.  However, instead of generating the shuffled deck by taking 1 card at a time from the bottom deck, then the top deck, and so forth, take \n",
    "$1+r$ cards from each pile, where $r \\sim Poisson(\\lambda)$ is i.i.d. for each instance you select cards form either pile.  Once you run out of cards in one pile, fill in the rest/bottom of the deck with the remaining cards in the other pile.\n",
    "\n",
    "Note that if $\\lambda=0$, this should represent a perfect in-shuffle.  As $\\lambda$ increases (appropriate values will likely be in $(0,2)$), our shuffle will more closely represent how a person actually shuffles.\n",
    "\n",
    "(Implementation hint: you may use the `.pop` function if you convert your deck to a list, but numpy has its own equivalent using `numpy.delete`.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommended API for checks:\n",
    "def rand_in_shuffle(deck, lam):\n",
    "    return(new_deck)\n",
    "\n",
    "\n",
    "#if lam=0, should be same as a regular in-shuffle\n",
    "# print(rand_in_shuffle(np.array(range(10)), 0))\n",
    "# print(in_shuffle(np.array(range(10))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Part 3 B: Random shuffle scoring; Extra Credit**\n",
    "\n",
    "**This part of the problem is for extra credit only.  It is not required.** \n",
    "\n",
    "Using `rand_in_shuffle(deck, lambda)`, experiment with different $\\lambda$ values ($\\lambda \\in [0,0.1,0.2,0.3,\\dots 2.9,3.0])$ to attempt to answer the following: If we were going to perform *exactly 6* random in-shuffles, what value of $\\lambda$ on average generates the deck that appears to be shuffled the most?  In other words, is there an amount of randomness that appears to be best in actually randomizing the deck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p2'></a>\n",
    "\n",
    "## [50 points] Problem 2: Multiple Linear Regression\n",
    "\n",
    "Load the data set in `houses`, with an opening snipper below.  The data includes sale prices of 24 houses from a midwetern town in the 1970's.   You are told that you need to quantify how price can be explained and predicted by the feature of the house.\n",
    "\n",
    "The variables available in the data set are labeled as follows:\n",
    "\n",
    "* sales:    the sales price of the house (in 1000s of dollars)\n",
    "* tax: \t    the local taxes\n",
    "* bath: \tthe number of bathrooms\n",
    "* lot: \t    the lot size (1000s of ft)\n",
    "* size: \tthe living space (1000s of ft)\n",
    "* garage: \tnumber of parking spots in the garage\n",
    "* rooms: \tnumber of rooms\n",
    "* bedrooms: number of bedrooms\n",
    "* age: \t    age in years\n",
    "* fire: \tnumber of fireplaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax</th>\n",
       "      <th>bath</th>\n",
       "      <th>lot</th>\n",
       "      <th>size</th>\n",
       "      <th>garage</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>age</th>\n",
       "      <th>fire</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.472</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.531</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.275</td>\n",
       "      <td>1.175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.050</td>\n",
       "      <td>1.232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.455</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tax  bath    lot   size  garage  rooms  bedrooms  age  fire  sales\n",
       "0  4.918   1.0  3.472  0.998     1.0      7         4   42     0   25.9\n",
       "1  5.021   1.0  3.531  1.500     2.0      7         4   62     0   29.5\n",
       "2  4.543   1.0  2.275  1.175     1.0      6         3   40     0   27.9\n",
       "3  4.557   1.0  4.050  1.232     1.0      6         3   54     0   25.9\n",
       "4  5.060   1.0  4.455  1.121     1.0      6         3   42     0   29.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/houses.txt', delimiter = \"\\t\")\n",
    "df.columns=['tax','bath','lot','size','garage','rooms','bedrooms','age','fire','sales']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Part 1: Fit your own model\n",
    "** Part 1 A: Explore**\n",
    "\n",
    "Make pairwise scatter plots of the continuous predictors/covariates, both against each other and against the outcome (expenditures).   Does the relationship between the independent variables and the dependent variables appear to be linear?  Do there appear to be independent variables that are collinear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 B: Make a Model**\n",
    "\n",
    "After removing any reasonably choices for columns from your work in part 1A, fit a model with the remaining columns.  Print its summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 C: Validate your Model**\n",
    "\n",
    "\n",
    "Perform a thorough discussion of the underlying regression assumptions of your model in part 1B.  You should plot a predictor vs. residuals plot for each column and histogram OR qqplot of the overall residuals.  Make sure to also check for non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 C: Tune your Model**\n",
    "\n",
    "\n",
    "Based on your work in parts 1B and 1C, **iterate** on your model.  Remove terms or add higher-order polynomials one at a time unless you are satisfied that your model captures the data as well as possible.  Each time you add or subtract a term from your model, you should repeat the steps in parts B and C: a summary table an exploration of assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 1 E: Explain your Model**\n",
    "\n",
    "**Justify** your choices: there are a lot of ways to choose a \"best\" model: we've mentioned e.g. only including significant predictors versus F-tests versus optimizing R-squared.  Explain what terms you chose and why they were appropriate! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Part 2: Let your Computer do it\n",
    "\n",
    "There are many methods to automate the analysis we did in part 1 of this problem.  These methods are never going to be as good as using your own eyes, but your computer is pretty powerful! \n",
    "\n",
    "Use `itertools.combinations` to perform a linear model (with no higher-order terms) on **every possible subset** of the 9 predictor variables to explain `sales`.  Report the one with the highest adjusted R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'), ('A', 'C'), ('B', 'C')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usage: all the combinations of size 2 of the given list.\n",
    "#your task: modify it to include the columns of the data frame, and ALL possible sizes\n",
    "# then fit a model for each and save/find the best adjusted R-squared\n",
    "\n",
    "list(itertools.combinations(['A','B','C'],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the resulting model differ from the one you arrived at in part 1?  Why or why not?  Do you prefer yours to the automated process?  (Ideally you do!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='bot'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
